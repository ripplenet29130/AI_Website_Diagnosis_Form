import { Handler, HandlerEvent } from '@netlify/functions';

/* ------------------------- å‹å®šç¾© ------------------------- */
interface LLMResponse {
  seo: string;
  ux: string;
  conversion: string;
  strengths: string;
  weaknesses: string;
  improvement: string;
}

/* ------------------------- AIé¸æŠ ------------------------- */
const AI_PROVIDER = process.env.AI_PROVIDER || "gemini";  // gemini / openai
const AI_MODEL = process.env.AI_MODEL || "gemini-2.0-flash";

/* ============================================================
   Gemini è§£æ
============================================================ */
async function analyzeWithGemini(htmlContent: string): Promise<LLMResponse> {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) throw new Error("GEMINI_API_KEY is not configured");

  const prompt = `ã‚ãªãŸã¯ãƒ—ãƒ­ã®Webã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®HTMLã‚’åˆ†æã—ã€èª­ã¿ã‚„ã™ãä¸å¯§ãªæ–‡ç« ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
ãƒ»å¿…ãšã€Œé©åº¦ãªæ”¹è¡Œã€ã‚’å…¥ã‚Œã¦èª­ã¿ã‚„ã™ãã—ã¦ãã ã•ã„
ãƒ»1ã¤ã®é …ç›®ã«ã¤ã 3ã€œ6 è¡Œç¨‹åº¦ã®æ®µè½ã«ã—ã¦ãã ã•ã„
ãƒ»ç®‡æ¡æ›¸ããŒã‚ã‚Œã°ãã®ã¾ã¾ç¶­æŒã—ã¦ OK
ãƒ»å°‚é–€ç”¨èªã¯ã§ãã‚‹ã ã‘å™›ã¿ç •ã„ãŸè¡¨ç¾ã«ã—ã¦ãã ã•ã„

ã€å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãš JSONï¼‰ã€‘
{
  "seo": "",
  "ux": "",
  "conversion": "",
  "strengths": "",
  "weaknesses": "",
  "improvement": ""
}

HTMLï¼ˆå†’é ­40,000æ–‡å­—ï¼‰:
${htmlContent.substring(0, 40000)}
`;

  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/${AI_MODEL}:generateContent?key=${apiKey}`,
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        contents: [{ parts: [{ text: prompt }] }],
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 2048,
          topK: 40,
          topP: 0.95,
        },
      }),
    }
  );

  const data = await response.json();

  if (data.error) throw new Error(data.error.message);

  const raw = data.candidates?.[0]?.content?.parts?.[0]?.text || "";

  const jsonStart = raw.indexOf("{");
  const jsonEnd = raw.lastIndexOf("}");
  if (jsonStart === -1 || jsonEnd === -1) throw new Error("Gemini JSONæŠ½å‡ºå¤±æ•—");

  return JSON.parse(raw.slice(jsonStart, jsonEnd + 1));
}

/* ============================================================
   OpenAI (ChatGPT) è§£æ
============================================================ */
async function analyzeWithOpenAI(htmlContent: string): Promise<LLMResponse> {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) throw new Error("OPENAI_API_KEY is not configured");

  const prompt = `ã‚ãªãŸã¯ãƒ—ãƒ­ã®Webã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®HTMLã‚’åˆ†æã—ã€èª­ã¿ã‚„ã™ãä¸å¯§ãªæ–‡ç« ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
ãƒ»å¿…ãšã€Œé©åº¦ãªæ”¹è¡Œã€ã‚’å…¥ã‚Œã¦èª­ã¿ã‚„ã™ãã—ã¦ãã ã•ã„
ãƒ»1ã¤ã®é …ç›®ã«ã¤ã 3ã€œ6 è¡Œç¨‹åº¦ã®æ®µè½ã«ã—ã¦ãã ã•ã„
ãƒ»ç®‡æ¡æ›¸ããŒã‚ã‚Œã°ãã®ã¾ã¾ç¶­æŒã—ã¦ OK
ãƒ»å°‚é–€ç”¨èªã¯ã§ãã‚‹ã ã‘å™›ã¿ç •ã„ãŸè¡¨ç¾ã«ã—ã¦ãã ã•ã„

ã€å¿…ãš JSON å½¢å¼ã§è¿”ã™ã€‘
{
  "seo": "",
  "ux": "",
  "conversion": "",
  "strengths": "",
  "weaknesses": "",
  "improvement": ""
}

HTMLï¼ˆå†’é ­40,000æ–‡å­—ï¼‰:
${htmlContent.substring(0, 40000)}
`;

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: AI_MODEL, // gpt-4o-mini ãªã©
      messages: [{ role: "user", content: prompt }],
      temperature: 0.4,
    }),
  });

  const data = await response.json();
  const text = data.choices?.[0]?.message?.content || "";

  const jsonStart = text.indexOf("{");
  const jsonEnd = text.lastIndexOf("}");

  if (jsonStart === -1 || jsonEnd === -1) {
    console.error("OpenAIè¿”å´:", text);
    throw new Error("OpenAI JSONæŠ½å‡ºå¤±æ•—");
  }

  return JSON.parse(text.slice(jsonStart, jsonEnd + 1));
}

/* ============================================================
   ãƒ¡ã‚¤ãƒ³ API Handler
============================================================ */
const handler: Handler = async (event: HandlerEvent) => {
  // CORS
  if (event.httpMethod === "OPTIONS") {
    return {
      statusCode: 200,
      headers: {
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Headers": "Content-Type",
        "Access-Control-Allow-Methods": "POST, OPTIONS",
      },
      body: "",
    };
  }

  if (event.httpMethod !== "POST") {
    return { statusCode: 405, body: JSON.stringify({ error: "Method not allowed" }) };
  }

  try {
    const body = JSON.parse(event.body || "{}");
    const { url } = body;

    if (!url) return { statusCode: 400, body: JSON.stringify({ error: "URL is required" }) };

    try { new URL(url); }
    catch { return { statusCode: 400, body: JSON.stringify({ error: "Invalid URL format" }) }; }

    // HTMLå–å¾—
    const res = await fetch(url, {
      headers: { "User-Agent": "Mozilla/5.0" },
      signal: AbortSignal.timeout(10000),
    });

    if (!res.ok) {
      return {
        statusCode: 400,
        body: JSON.stringify({ error: `Failed to fetch URL: ${res.status}` }),
      };
    }

    const htmlContent = await res.text();

    // ğŸ”¥ AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ã‚’è‡ªå‹•é¸æŠ
    const result =
      AI_PROVIDER === "openai"
        ? await analyzeWithOpenAI(htmlContent)
        : await analyzeWithGemini(htmlContent);

    return {
      statusCode: 200,
      headers: {
        "Content-Type": "application/json",
        "Access-Control-Allow-Origin": "*",
      },
      body: JSON.stringify(result),
    };

  } catch (err: any) {
    console.error("ERROR:", err);

    return {
      statusCode: 500,
      headers: {
        "Content-Type": "application/json",
        "Access-Control-Allow-Origin": "*",
      },
      body: JSON.stringify({ error: err.message || "Internal server error" }),
    };
  }
};

export { handler };
